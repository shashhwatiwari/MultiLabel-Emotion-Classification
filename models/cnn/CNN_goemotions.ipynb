{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c23c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import pickle\n",
    "from datasets import load_dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Conv1D, GlobalMaxPooling1D,\n",
    "    concatenate, Dropout, Dense\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9bb188",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73283995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GoEmotions\n",
    "dataset = load_dataset(\"go_emotions\")\n",
    "train_texts = dataset[\"train\"][\"text\"]\n",
    "val_texts   = dataset[\"validation\"][\"text\"]\n",
    "test_texts  = dataset[\"test\"][\"text\"]\n",
    "train_labels = dataset[\"train\"][\"labels\"]\n",
    "val_labels   = dataset[\"validation\"][\"labels\"]\n",
    "test_labels  = dataset[\"test\"][\"labels\"]\n",
    "label_names  = dataset[\"train\"].features[\"labels\"].feature.names  # 28 emotion labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63717674",
   "metadata": {},
   "source": [
    "### Tokenization and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi‑hot encode labels\n",
    "num_labels = len(label_names)\n",
    "def to_multi_hot(label_lists):\n",
    "    m = np.zeros((len(label_lists), num_labels), dtype=np.int32)\n",
    "    for i, labs in enumerate(label_lists):\n",
    "        m[i, labs] = 1\n",
    "    return m\n",
    "\n",
    "y_train = to_multi_hot(train_labels)\n",
    "y_val   = to_multi_hot(val_labels)\n",
    "y_test  = to_multi_hot(test_labels)\n",
    "\n",
    "# Tokenize and pad\n",
    "vocab_size = 20000  \n",
    "max_len    = 100     \n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f008fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer_goemotions.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(\"Tokenizer saved to tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3da936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(texts):\n",
    "    seq = tokenizer.texts_to_sequences(texts)\n",
    "    return pad_sequences(seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "X_train = encode(train_texts)\n",
    "X_val   = encode(val_texts)\n",
    "X_test  = encode(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbc4ec",
   "metadata": {},
   "source": [
    "### Model architecture and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model architecture\n",
    "embedding_dim = 128       \n",
    "filter_sizes  = [3,4,5]   \n",
    "num_filters   = 128       \n",
    "drop_rate     = 0.5       \n",
    "\n",
    "inputs = Input(shape=(max_len,), dtype=\"int32\")\n",
    "embed  = Embedding(vocab_size, embedding_dim, input_length=max_len)(inputs)\n",
    "\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Conv1D(filters=num_filters, kernel_size=sz, activation=\"relu\")(embed)\n",
    "    pool = GlobalMaxPooling1D()(conv)\n",
    "    conv_blocks.append(pool)\n",
    "\n",
    "concat = concatenate(conv_blocks)\n",
    "drop   = Dropout(drop_rate)(concat)\n",
    "output = Dense(num_labels, activation=\"sigmoid\")(drop)\n",
    "\n",
    "model = Model(inputs, output)\n",
    "\n",
    "# Compile & train\n",
    "learning_rate = 1e-3\n",
    "batch_size    = 64\n",
    "epochs        = 5\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d4aec0",
   "metadata": {},
   "source": [
    "### Evaluation and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffbc78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "pred_probs = model.predict(X_test, batch_size=batch_size)\n",
    "y_pred     = (pred_probs >= 0.5).astype(int)\n",
    "\n",
    "# Keras evaluation (loss + element‑wise accuracy)\n",
    "loss, keras_acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print(f\"\\nTest Loss: {loss:.4f}\")\n",
    "print(f\"Keras Accuracy (element‑wise): {keras_acc:.4f}\")\n",
    "\n",
    "# Raw accuracy (fraction of individual label predictions correct)\n",
    "raw_acc = accuracy_score(\n",
    "    y_test.flatten(),\n",
    "    y_pred.flatten()\n",
    ")\n",
    "print(f\"Raw Accuracy (sklearn, element‑wise): {raw_acc:.4f}\")\n",
    "\n",
    "# Micro‑averaged F1 (treats every label equally across all samples)\n",
    "micro_f1 = f1_score(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    average='micro',\n",
    "    zero_division=0\n",
    ")\n",
    "print(f\"Micro-averaged F1 score: {micro_f1:.4f}\\n\")\n",
    "\n",
    "# Full per‑label classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=label_names,\n",
    "    zero_division=0,\n",
    "    digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aca200",
   "metadata": {},
   "source": [
    "### Code cell for interactive testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66aa672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive prediction function\n",
    "def predict_emotions(text, top_k=5, threshold=0.2):\n",
    "    seq    = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(seq, maxlen=max_len, padding='post', truncating='post')\n",
    "    preds  = model.predict(padded)[0]\n",
    "    # pair labels with scores and sort\n",
    "    pairs = sorted(zip(label_names, preds), key=lambda x: x[1], reverse=True)\n",
    "    return [(label, float(score)) for label, score in pairs if score >= threshold][:top_k]\n",
    "\n",
    "def interactive_predict_emotions():\n",
    "    print(\"\\nEnter a sentence to classify emotions (type 'quit' to exit):\")\n",
    "    while True:\n",
    "        user_input = input(\"> \")\n",
    "        if user_input.lower() in (\"quit\", \"exit\"):\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        results = predict_emotions(user_input)\n",
    "        if results:\n",
    "            print(\"Predicted emotions:\")\n",
    "            for label, score in results:\n",
    "                print(f\"  {label:>10s}: {score:.3f}\")\n",
    "        else:\n",
    "            print(\"No emotion score exceeded the threshold. Try a different sentence.\")\n",
    "\n",
    "#interactive_predict_emotions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb82a4",
   "metadata": {},
   "source": [
    "### Code cell to export and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb785047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_and_zip(model,\n",
    "                   model_filename='cnn_goemotions.h5',\n",
    "                   zip_filename='cnn_goemotions.zip'):\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(model_filename)\n",
    "    print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "#export_and_zip(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
