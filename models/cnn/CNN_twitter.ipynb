{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b449213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "import zipfile\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bdbd1",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset     = load_dataset(\"dair-ai/emotion\")\n",
    "train_texts = dataset[\"train\"][\"text\"]\n",
    "train_labels= dataset[\"train\"][\"label\"]\n",
    "val_texts   = dataset[\"validation\"][\"text\"]\n",
    "val_labels  = dataset[\"validation\"][\"label\"]\n",
    "test_texts  = dataset[\"test\"][\"text\"]\n",
    "test_labels = dataset[\"test\"][\"label\"]\n",
    "\n",
    "label_names = dataset[\"train\"].features[\"label\"].names\n",
    "num_classes = len(label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3b637",
   "metadata": {},
   "source": [
    "### Hyperparameters and tokenization and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7638c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "vocab_size     = 10000\n",
    "embedding_dim  = 100\n",
    "max_length     = 100\n",
    "padding_type   = 'post'\n",
    "trunc_type     = 'post'\n",
    "oov_token      = \"<OOV>\"\n",
    "\n",
    "filters        = 128\n",
    "kernel_size    = 5\n",
    "hidden_units   = 64\n",
    "dropout_rate   = 0.5\n",
    "\n",
    "learning_rate  = 1e-3\n",
    "batch_size     = 32\n",
    "epochs         = 10\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe448a2f",
   "metadata": {},
   "source": [
    "Code cell to save tokenizer file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer_twitter.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(\"Tokenizer saved to tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1867e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_texts(texts):\n",
    "    seqs   = tokenizer.texts_to_sequences(texts)\n",
    "    return pad_sequences(seqs, maxlen=max_length,\n",
    "                         padding=padding_type,\n",
    "                         truncating=trunc_type)\n",
    "\n",
    "X_train = prep_texts(train_texts)\n",
    "X_val   = prep_texts(val_texts)\n",
    "X_test  = prep_texts(test_texts)\n",
    "\n",
    "y_train = np.eye(num_classes)[train_labels]\n",
    "y_val   = np.eye(num_classes)[val_labels]\n",
    "y_test  = np.eye(num_classes)[test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a44e81",
   "metadata": {},
   "source": [
    "### Model architecture and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39987884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build & compile the 1D‑CNN\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
    "    Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(hidden_units, activation='relu'),\n",
    "    Dropout(dropout_rate),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f892f1c",
   "metadata": {},
   "source": [
    "### Results and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae361b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing & Classification Report\n",
    "# Evaluate overall test loss & accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.2%} — Loss: {test_loss:.4f}\\n\")\n",
    "\n",
    "# Detailed per-class metrics\n",
    "y_pred_probs = model.predict(X_test, batch_size=batch_size)\n",
    "y_pred       = np.argmax(y_pred_probs, axis=1)\n",
    "y_true       = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=label_names,\n",
    "    digits=4\n",
    ")\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b078c7",
   "metadata": {},
   "source": [
    "### Code cell for interactive testing of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb1662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive prediction helper\n",
    "def predict_emotion(text: str):\n",
    "    seq    = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(seq, maxlen=max_length,\n",
    "                           padding=padding_type,\n",
    "                           truncating=trunc_type)\n",
    "    probs  = model.predict(padded)[0]\n",
    "    idx    = np.argmax(probs)\n",
    "    return label_names[idx], probs[idx]\n",
    "\n",
    "# Interactive prediction function\n",
    "# Uncomment to enable interactive mode\n",
    "def interactive_predict():\n",
    "    print(\"Enter a sentence (or 'quit' to stop):\")\n",
    "    while True:\n",
    "        text = input(\"> \")\n",
    "        if text.lower() in ('quit', 'exit'):\n",
    "            break\n",
    "        label, confidence = predict_emotion(text)\n",
    "        print(f\"Predicted: {label}  (confidence {confidence:.2%})\")\n",
    "\n",
    "#interactive_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed2387",
   "metadata": {},
   "source": [
    "### Code cell to export and save the model on the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_and_zip(model,\n",
    "                   model_filename='cnn_twitter.h5',\n",
    "                   zip_filename='cnn_twitter.zip'):\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(model_filename)\n",
    "    print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "#export_and_zip(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
